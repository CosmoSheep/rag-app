#!/usr/bin/env python3
"""
app.py - FastAPI æœåŠ¡
æä¾› /chat æ¥å£ï¼ŒåŸºäº FAISS ç´¢å¼•è¿›è¡Œ RAG é—®ç­”
"""
import os
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# æ£€æŸ¥ API Key
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")

app = FastAPI(title="RAG Demo API")

# åŠ è½½ FAISS ç´¢å¼•
print("ğŸ”„ æ­£åœ¨åŠ è½½ FAISS ç´¢å¼•...")
embeddings = OpenAIEmbeddings()
vectorstore = FAISS.load_local(
    "faiss_index", 
    embeddings,
    allow_dangerous_deserialization=True
)
print("âœ… FAISS ç´¢å¼•åŠ è½½å®Œæˆ")

# åˆ›å»º LLM
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.7,
)

# è‡ªå®šä¹‰ Prompt
prompt_template = """ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†é—®ç­”åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·ç¤¼è²Œåœ°å‘Šè¯‰ç”¨æˆ·"çŸ¥è¯†åº“ä¸­å¯èƒ½æ²¡æœ‰ç›¸å…³å†…å®¹"ã€‚

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{question}

å›ç­”ï¼š"""

PROMPT = PromptTemplate(
    template=prompt_template,
    input_variables=["context", "question"]
)

# åˆ›å»º QA Chain
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
    chain_type_kwargs={"prompt": PROMPT},
    return_source_documents=False,
)

class ChatRequest(BaseModel):
    question: str

class ChatResponse(BaseModel):
    answer: str

@app.get("/")
def read_root():
    return {
        "message": "RAG Demo API is running",
        "endpoints": {
            "/chat": "POST - å‘é€é—®é¢˜è·å–ç­”æ¡ˆ",
            "/health": "GET - å¥åº·æ£€æŸ¥"
        }
    }

@app.get("/health")
def health_check():
    return {"status": "healthy"}

@app.post("/chat", response_model=ChatResponse)
def chat(request: ChatRequest):
    if not request.question or not request.question.strip():
        raise HTTPException(status_code=400, detail="é—®é¢˜ä¸èƒ½ä¸ºç©º")
    
    try:
        result = qa_chain.invoke({"query": request.question})
        answer = result.get("result", "æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆå›ç­”")
        return ChatResponse(answer=answer)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™ï¼š{str(e)}")

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)

