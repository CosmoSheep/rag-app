[项目介绍]

这是一个基于 LangChain 的简单 RAG（Retrieval-Augmented Generation）问答应用，用来完成 W1001a 作业。

它的知识库来自一个本地的 data.txt 文件，通过向量化后存入 FAISS 索引。

应用使用 FastAPI 暴露一个 /chat 接口，对用户问题进行检索增强问答。



[技术栈]

这个项目使用的核心技术包括：

1. LangChain：负责把向量检索和大模型调用串成一个 chain。

2. FAISS：用来做向量相似度搜索，并把索引持久化到 faiss_index 目录。

3. FastAPI：提供 Web API 服务。

4. Docker：把应用和 faiss_index 一起打包成容器镜像。

5. AWS App Runner：用来部署容器并提供托管服务。

6. GitHub Actions + OIDC：在代码 push 到 main 分支时自动构建并部署。



[应用行为]

用户通过 /chat 接口发送自然语言问题。

系统会先在本地向量库中检索与问题最相关的文本片段，然后把这些片段和问题一起发送给大模型。

大模型根据检索到的上下文生成答案。

如果知识库中没有相关信息，系统应该礼貌地说明"知识库中可能没有相关内容"。



[知识覆盖范围]

目前的知识库只包含关于这个 RAG demo 的说明信息和少量作者背景。

它更适合回答与本项目相关的问题，例如：

- 这个 RAG demo 是做什么用的？

- 它用到了哪些技术栈？

- 部署的大致流程是什么？

对于和项目无关的领域知识，这个系统可能无法给出准确答案。



[部署流程摘要]

这个项目预期的部署流程大致如下：

1. 在本地运行 ingest.py，从 data.txt 构建 FAISS 索引并保存到 faiss_index 目录。

2. 使用 Dockerfile 构建包含 faiss_index 的镜像。

3. 使用 Terraform 在 AWS 上创建 ECR 仓库、App Runner 服务和 GitHub OIDC 角色。

4. 配置 GitHub Actions，通过 OIDC 登录 AWS，构建并推送镜像到 ECR，然后触发 App Runner 部署。

5. 使用 Cloudflare 把自定义域名的 CNAME 指向 App Runner 的默认域名。



[常见问题]

问：这个 demo 支持多轮对话记忆吗？

答：当前版本只实现了最小的单轮问答，每个问题独立处理，没有对话记忆。



问：知识库更新需要怎么做？

答：修改 data.txt 后，需要重新运行 ingest.py 来生成新的 faiss_index，然后重新构建并部署容器。



问：这个项目适合作为生产环境系统吗？

答：这个项目主要用于教学和作业演示，架构和提示词都比较简单。

如果要用于生产，需要增加日志、监控、鉴权、配额控制以及更稳健的 prompt 设计。



[作者简介]

这个 RAG demo 的作者是一名对 AI Native 产品开发感兴趣的工程师，擅长机器学习建模和工程化落地。

她希望通过这个小项目，把"从本地脚本到云端可访问服务"的全链路打通。

